import os
import json
import requests
import psycopg2
from psycopg2.extras import execute_values
from datetime import date, timedelta
from dateutil import parser

# ================== CONFIG ==================

FB_API_VERSION = "v17.0"

# JSON-Ð¼Ð°ÑÑÐ¸Ð² Ñ Ñ‚Ð¾ÐºÐµÐ½Ð°Ð¼Ð¸, Ñ‚Ð°Ñ€Ð³ÐµÑ‚Ð¾Ð»Ð¾Ð³Ð°Ð¼Ð¸ Ð¸ ÑÐ¿Ð¸ÑÐºÐ¾Ð¼ Ð°ÐºÐºÐ°ÑƒÐ½Ñ‚Ð¾Ð².
# Ð‘ÐµÑ€Ñ‘Ñ‚ÑÑ Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ FB_CONFIG (GitHub Secret).
FB_CONFIG_RAW = os.getenv("FB_CONFIG")

# Ð¡Ñ‚Ñ€Ð¾ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº Neon (Postgres).
# Ð’ workflow Ð¼Ñ‹ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ð¼ ÐµÑ‘ Ñ‡ÐµÑ€ÐµÐ· secrets.DATABASE_URL â†’ PG_DSN.
PG_DSN = os.getenv("PG_DSN") or os.getenv("DATABASE_URL")

# Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð´Ð½ÐµÐ¹ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‚ÑÐ½ÑƒÑ‚ÑŒ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐµ (ÐµÑÐ»Ð¸ watermark ÐµÑ‰Ñ‘ Ð½ÐµÑ‚).
DEFAULT_DAYS_BACK = int(os.getenv("FB_DEFAULT_DAYS_BACK", "60"))

# Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… Ð´Ð½ÐµÐ¹ Ð¿ÐµÑ€ÐµÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸ ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐµ.
RELOAD_LAST_DAYS = int(os.getenv("FB_RELOAD_LAST_DAYS", "3"))

# ÐŸÐ¾Ð»Ñ Ð´Ð»Ñ insights
FIELDS = [
    "date_start",
    "account_id",
    "account_name",
    "campaign_id",
    "campaign_name",
    "adset_id",
    "adset_name",
    "ad_id",
    "ad_name",
    "impressions",
    "clicks",
    "spend",
    "reach",
    "frequency",
    "ctr",
    "cpc",
    "cpp",
    "actions"   # ðŸ‘ˆ Ð·Ð´ÐµÑÑŒ Ð·Ð°Ð±ÐµÑ€Ñ‘Ð¼ Ð»Ð¸Ð´Ñ‹
]

# ================== DB HELPERS ==================


def get_conn():
    if not PG_DSN:
        raise RuntimeError("PG_DSN / DATABASE_URL is not set")
    return psycopg2.connect(PG_DSN)


def ensure_tables(conn):
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼/Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, ÐµÑÐ»Ð¸ Ð¸Ñ… ÐµÑ‰Ñ‘ Ð½ÐµÑ‚."""
    with conn.cursor() as cur:
        cur.execute("""
        CREATE TABLE IF NOT EXISTS fb_insights_daily (
            date           date                NOT NULL,
            account_id     text                NOT NULL,
            account_name   text,
            campaign_id    text,
            campaign_name  text,
            adset_id       text,
            adset_name     text,
            ad_id          text                NOT NULL,
            ad_name        text,
            impressions    bigint,
            clicks         bigint,
            leads          bigint,
            spend          numeric(18,4),
            reach          bigint,
            frequency      numeric(10,4),
            ctr            numeric(10,4),
            cpc            numeric(18,4),
            cpp            numeric(18,4),
            targetologist  text,
            updated_at     timestamptz DEFAULT now(),
            PRIMARY KEY (date, account_id, ad_id)
        );
        """)
        # Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹, ÐµÑÐ»Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð»Ð° Ñ€Ð°Ð½ÑŒÑˆÐµ Ð±ÐµÐ· Ð½Ð¾Ð²Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
        cur.execute("ALTER TABLE fb_insights_daily ADD COLUMN IF NOT EXISTS account_name text;")
        cur.execute("ALTER TABLE fb_insights_daily ADD COLUMN IF NOT EXISTS leads bigint;")

        cur.execute("""
        CREATE TABLE IF NOT EXISTS fb_watermark (
            account_id text PRIMARY KEY,
            last_date  date,
            updated_at timestamptz DEFAULT now()
        );
        """)
        conn.commit()


def get_watermark(conn, account_id):
    with conn.cursor() as cur:
        cur.execute("SELECT last_date FROM fb_watermark WHERE account_id = %s", (account_id,))
        row = cur.fetchone()
        if row and row[0]:
            return row[0]
    return None


def set_watermark(conn, account_id, last_date):
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO fb_watermark (account_id, last_date, updated_at)
            VALUES (%s, %s, now())
            ON CONFLICT (account_id) DO UPDATE
                SET last_date = EXCLUDED.last_date,
                    updated_at = now();
        """, (account_id, last_date))
        conn.commit()


# ================== FB HELPERS ==================


def extract_leads(actions):
    """
    actions â€” ÑÐ¿Ð¸ÑÐ¾Ðº ÑÐ»Ð¾Ð²Ð°Ñ€ÐµÐ¹ Ð²Ð¸Ð´Ð°:
    [{"action_type": "lead", "value": "3"}, ...]
    Ð¡ÑƒÐ¼Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ, Ñ‡Ñ‚Ð¾ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÑÑ Ðº Ð»Ð¸Ð´Ð°Ð¼.
    """
    if not actions:
        return 0

    total = 0
    for a in actions:
        t = a.get("action_type")
        if t in (
            "lead",
            "onsite_conversion.lead_grouped",
            "offsite_conversion.fb_pixel_lead",
            "offsite_conversion.lead"
        ):
            try:
                total += int(a.get("value") or 0)
            except (TypeError, ValueError):
                pass
    return total


def fetch_insights_for_account(token, account_id, date_from, date_to, targetologist):
    """
    Ð¢ÑÐ½ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸ÑÐ¼ Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´ [date_from, date_to]
    c ÑˆÐ°Ð³Ð¾Ð¼ 1 Ð´ÐµÐ½ÑŒ (time_increment=1) Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ account_id.
    """
    print(f"***FB*** Fetch {account_id} ({targetologist}) from {date_from} to {date_to}")

    url = f"https://graph.facebook.com/{FB_API_VERSION}/act_{account_id}/insights"

    params = {
        "access_token": token,
        "time_range": json.dumps({
            "since": date_from.isoformat(),
            "until": date_to.isoformat()
        }),
        "time_increment": 1,
        "level": "ad",
        "fields": ",".join(FIELDS),
        "limit": 500
    }

    all_rows = []
    page = 1

    while True:
        resp = requests.get(url, params=params)

        if resp.status_code != 200:
            try:
                err_json = resp.json()
            except Exception:
                err_json = resp.text
            print(f"***ERROR*** FB API error for account {account_id} ({targetologist}), "
                  f"status={resp.status_code}, response={err_json}")
            return None

        try:
            data = resp.json()
        except Exception as e:
            print(f"***ERROR*** Cannot parse JSON for account {account_id} ({targetologist}): {e}")
            print("Raw response:", resp.text[:500])
            return None

        for item in data.get("data", []):
            dt = parser.isoparse(item["date_start"]).date() if "date_start" in item else None

            leads = extract_leads(item.get("actions"))

            row = {
                "date": dt,
                "account_id": item.get("account_id"),
                "account_name": item.get("account_name"),
                "campaign_id": item.get("campaign_id"),
                "campaign_name": item.get("campaign_name"),
                "adset_id": item.get("adset_id"),
                "adset_name": item.get("adset_name"),
                "ad_id": item.get("ad_id"),
                "ad_name": item.get("ad_name"),
                "impressions": int(item.get("impressions") or 0),
                "clicks": int(item.get("clicks") or 0),
                "leads": leads,
                "spend": float(item.get("spend") or 0),
                "reach": int(item.get("reach") or 0) if item.get("reach") else None,
                "frequency": float(item.get("frequency") or 0) if item.get("frequency") else None,
                "ctr": float(item.get("ctr") or 0) if item.get("ctr") else None,
                "cpc": float(item.get("cpc") or 0) if item.get("cpc") else None,
                "cpp": float(item.get("cpp") or 0) if item.get("cpp") else None,
                "targetologist": targetologist
            }
            all_rows.append(row)

        paging = data.get("paging", {})
        next_url = paging.get("next")
        if not next_url:
            break

        url = next_url
        params = {}
        page += 1

    print(f"***FB*** {account_id} ({targetologist}): {len(all_rows)} rows fetched")
    return all_rows


def upsert_insights(conn, rows):
    """Upsert ÑÑ‚Ñ€Ð¾Ðº Ð² fb_insights_daily."""
    if not rows:
        return

    cols = [
        "date",
        "account_id",
        "account_name",
        "campaign_id",
        "campaign_name",
        "adset_id",
        "adset_name",
        "ad_id",
        "ad_name",
        "impressions",
        "clicks",
        "leads",
        "spend",
        "reach",
        "frequency",
        "ctr",
        "cpc",
        "cpp",
        "targetologist"
    ]

    values = [[r[c] for c in cols] for r in rows]

    with conn.cursor() as cur:
        sql = f"""
        INSERT INTO fb_insights_daily ({", ".join(cols)})
        VALUES %s
        ON CONFLICT (date, account_id, ad_id) DO UPDATE
        SET
            account_name  = EXCLUDED.account_name,
            campaign_id   = EXCLUDED.campaign_id,
            campaign_name = EXCLUDED.campaign_name,
            adset_id      = EXCLUDED.adset_id,
            adset_name    = EXCLUDED.adset_name,
            ad_name       = EXCLUDED.ad_name,
            impressions   = EXCLUDED.impressions,
            clicks        = EXCLUDED.clicks,
            leads         = EXCLUDED.leads,
            spend         = EXCLUDED.spend,
            reach         = EXCLUDED.reach,
            frequency     = EXCLUDED.frequency,
            ctr           = EXCLUDED.ctr,
            cpc           = EXCLUDED.cpc,
            cpp           = EXCLUDED.cpp,
            targetologist = EXCLUDED.targetologist,
            updated_at    = now();
        """
        execute_values(cur, sql, values, page_size=500)
        conn.commit()

    print(f"***DB*** Upserted {len(rows)} rows into fb_insights_daily")


# ================== MAIN ==================


def main():
    if not FB_CONFIG_RAW:
        raise RuntimeError("FB_CONFIG is not set")

    config = json.loads(FB_CONFIG_RAW)
    if not isinstance(config, list) or not config:
        raise RuntimeError("FB_CONFIG must be a non-empty JSON array")

    conn = get_conn()
    ensure_tables(conn)

    today = date.today()
    target_to = today  # Ñ‚ÑÐ½ÐµÐ¼ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ ÑÐµÐ³Ð¾Ð´Ð½ÑÑˆÐ½Ð¸Ð¹ Ð´ÐµÐ½ÑŒ

    for cfg in config:
        token = cfg.get("token")
        targetologist = cfg.get("targetologist") or "unknown"
        ids = cfg.get("ids", [])

        if not token or not ids:
            print(f"***WARN*** Skipping config without token or ids: {cfg}")
            continue

        for acc in ids:
            # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ act_, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
            if acc.startswith("act_"):
                account_id = acc[4:]
            else:
                account_id = acc

            try:
                last = get_watermark(conn, account_id)
                if last:
                    date_from = last - timedelta(days=RELOAD_LAST_DAYS)
                else:
                    date_from = today - timedelta(days=DEFAULT_DAYS_BACK)

                if date_from > target_to:
                    print(f"***SKIP*** {account_id} ({targetologist}): date_from > date_to")
                    continue

                rows = fetch_insights_for_account(
                    token=token,
                    account_id=account_id,
                    date_from=date_from,
                    date_to=target_to,
                    targetologist=targetologist
                )

                if rows is None:
                    print(f"***WARN*** {account_id} ({targetologist}): FB returned error, "
                          f"skipping upsert and watermark update")
                    continue

                if not rows:
                    print(f"***WARN*** {account_id} ({targetologist}): no data, "
                          f"skipping upsert and watermark update")
                    continue

                upsert_insights(conn, rows)
                set_watermark(conn, account_id, target_to)

            except Exception as e:
                print(f"***ERROR*** Unexpected error for account {account_id} ({targetologist}): {e}")

    conn.close()
    print("***OK*** Finished FB â†’ Neon incremental load with leads")


if __name__ == "__main__":
    main()
